---
title: "parse_burst_ema_data"
author: "Aditya Ponnada"
date: "6/7/2021"
output: html_document
---
## Import libraries
```{r}
library(psych)
library(dplyr)
library(plyr)
library(reshape2)

```

## Read and combine the csv files for EOD
```{r}
pre_process_root_path = "D:/new_data_pre_processed/ema_promptresponse/"

# file_pattern <- paste0(pre_process_root_path, '/*/phone_promptresponse_clean_*.csv')
file_pattern <- paste0(pre_process_root_path, '/*@timestudy_com.csv')
```

## Combine and read all the files for EMA
```{r}

pattern_files_found <- Sys.glob(file_pattern)

# list_of_files <- list.files(pattern_files_found, recursive = TRUE, full.names = TRUE)
list_of_files <- list.files(path = pre_process_root_path, pattern = NULL, full.names = TRUE)

# combined_uema_file <- do.call(plyr::rbind.fill(), lapply(pattern_files_found, read.csv))
combined_ema_file <- ldply(list_of_files, read.csv, header = TRUE, na.strings = c("", "NA"))

```


## Filter out daily prompts on TIME days
```{r}

# combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "Daily" & combined_ema_file$Study_Mode == "TIME")
combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "EMA" & combined_ema_file$Study_Mode == "BURST")

```

## Remove never prompted
```{r}
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status != "NeverPrompted")
```


## Filter out never started or neverprompted prompts
```{r}
include_status <- c("Started", "Completed", "PartiallyCompleted")
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status %in% include_status)
```


## Filter out unwanted columns
```{r}

combined_ema_time_daily_df <- combined_ema_time_daily_df[, c(1:109)]

```

## get column pair lists
```{r}
question_column_set_list <- names(combined_ema_time_daily_df[, c(34:109)])
```

First describe the set types:
Question ID columns 1, 5, ... i = 1, i + 4
Question_text columns, 2, 6, ... i = 2, i + 4
Answer_text columns, 3, 7 ... i = 3, i + 4
Answer_time columns, 4, 8, ... i = 4, i + 4
```{r}

get_column_type_list <- function(start_index, col_list){
  
  type_list <- c()
  num_iters <- length(col_list)/4
  for (i in 1:num_iters){
    type_list <- c(type_list, col_list[[start_index]])
    start_index = start_index + 4
    
  }
  
  return(type_list)
  
}

```

## Get type lists
```{r}
Q_ID_cols <- get_column_type_list(1, question_column_set_list)
Q_text_cols <- get_column_type_list(2, question_column_set_list)
ans_text_cols <- get_column_type_list(3, question_column_set_list)
ans_time_cols <- get_column_type_list(4, question_column_set_list)
```

## Convert to long format
```{r}

time_daily_long_df <- reshape(combined_ema_time_daily_df, direction="long", 
        varying=list(Q_ID_cols, Q_text_cols, ans_text_cols, ans_time_cols), 
        v.names=c("Q_D","Q_TEXT","ANS_TEXT", "ANS_TIME"))

```

## Group by P_ID and then sort by time
```{r}
time_daily_long_df <- time_daily_long_df[order(time_daily_long_df$Participant_ID, time_daily_long_df$Initial_Prompt_Local_Time), ]
```

## Filter out unwanted questions
```{r}
questions_to_include <- c("Q1_SAD", "Q2_HAPP", "Q3_FATIG", "Q4_END", "Q5_REL", "Q6_TEN", "Q7_STRESS", "Q8_FRUST", "Q9_NERV", "Q10_FOC", "Q11_RESIST", "Q12_DEM", "Q14_ROUT", "Q15_SICK")
```

Only select these rows
```{r}
time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$Q_D %in% questions_to_include)
```

## Convert the prompt time to date time object
```{r}
time_daily_long_df$prompt_date_time <- as.POSIXct(time_daily_long_df$Initial_Prompt_Local_Time, format="%Y-%m-%d %H:%M:%OS")
```

## Temporarily remove data before june 1 2020
```{r}
filter_date <- as.POSIXct("2020-06-01 00:00:00.000", format="%Y-%m-%d %H:%M:%OS")

time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$prompt_date_time >= filter_date)
```

## Remove the Q* from question id
```{r}

# pattern = "[Q]{1}\d{1,2}_"

time_daily_long_df$Q_ID <- gsub('[Q]{1}\\d{1,2}_', '', time_daily_long_df$Q_D)

```

Convert the question text to quotes
```{r}
time_daily_long_df$Q_TEXT <- paste0("'", time_daily_long_df$Q_TEXT, "'")
```


## Read the daily report file
```{r}


combined_report_file = paste0('D:/new_data_pre_processed', '/combined_report_N70.csv')
combined_report_df <- read.csv(combined_report_file, header = TRUE, sep = ',')

```

## Convert sleep wake times to date time objects
```{r}


combined_report_df$current_wake_time <- as.POSIXct(combined_report_df$current_wake_time, format="%Y-%m-%d %H:%M:%S")
combined_report_df$current_sleep_time <- as.POSIXct(combined_report_df$current_sleep_time, format="%Y-%m-%d %H:%M:%S")

```

## Rescore burst EMA
Scoring method:
Extremely, Very much so, and quite a bit --> "Yes" --> 3
Moderately, a little --> 2 (sort of)
Not at all --> No --> 1
```{r}

time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Extremely" | time_daily_long_df$ANS_TEXT == "Quite a bit" | time_daily_long_df$ANS_TEXT == "Very much so"] <- 3
time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Moderately" | time_daily_long_df$ANS_TEXT == "A little"] <- 2
time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Not at all"] <- 1


```

Remove unwanted answer types
```{r}
answers_to_include <- c("Very much so", "Extremely", "Quite a bit", "Moderately", "A little", "Not at all")
time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$ANS_TEXT %in% answers_to_include)
```


## Add domain to P-ID

```{r}

time_daily_long_df$P_ID <- paste0(time_daily_long_df$Participant_ID,  "@timestudy_com")

```


## Convert question id to lower case
```{r}

time_daily_long_df$Q_ID <- tolower(time_daily_long_df$Q_ID)

```



## create a subset for participant
uEMA combined file

```{r}

get_bEMA_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$P_ID == p_id)
  return(pid_df)
}

```

Combined report file
```{r}

get_report_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$participant_ID == p_id)
  pid_df <- subset(pid_df, pid_df$study_mode == "BURST")
  return(pid_df)
}

```

## Create a subset for the construct
uEMA combined file

```{r}

get_bEMA_pid_var_df <- function(df, variable){
  var_df <- subset(df, df$Q_ID == variable)
  # sample rows here
  if (nrow(var_df) != 0){
    var_df <- var_df[sample(nrow(var_df), 5), ]
  }
  return(var_df)
}

```

## get p_id_subset
```{r}

prepare_pid_subset <- function(df, report_df, p_id) {
  # print(p_id)
  pid_subset_df <- get_bEMA_pid_df(df, p_id)
  # print(head(pid_subset_df))
  pid_report_df <- get_report_pid_df(report_df, p_id)
  # print(head(pid_report_df))
  # pid_subset_df <- subset(pid_subset_df, pid_subset_df$Q_ID != "activity")
  nrow_report <- nrow(pid_report_df)
  
  for(i in 1:nrow(pid_report_df)){
    # print(i)
  # print(paste0(i, " _ ", pid_report_df$current_wake_time[i]))
  pid_subset_df$wake_period[pid_subset_df$prompt_date_time >= pid_report_df$current_wake_time[i] & pid_subset_df$prompt_date_time <= pid_report_df$current_sleep_time[i]] <- paste0("Wake_period_", i)
  # print(paste0("Wake_period_", i))
  }
  
  return(pid_subset_df)
  
}

```

Add a test function to get the wake period along with prompt response file for all participants
```{r}

plist <- unique(time_daily_long_df$P_ID)

bema_wp_df <- data.frame()

for (pid in plist){
  p_temp_df <- prepare_pid_subset(time_daily_long_df, combined_report_df, pid)
  bema_wp_df <- rbind(bema_wp_df, p_temp_df)
}

```

write the dataframe to a csv file
```{r}
write.csv(bema_wp_df, file="D:/uema_exploratory_plots/trajectory_plots/bema_wp_export.csv", row.names = FALSE, quote = FALSE, sep = ",")
```


## Create a slope type function
```{r}

get_slope_type <- function(slist, vlist){
  slope_type = ""
  slist <- slist[!is.na(slist)]
  vlist <- vlist[!is.na(vlist)]
  # print("Slope list: ")
  # print(slist)
  # print("value list: ")
  # print(vlist)
  # print(length(unique(vlist)))
  # print(unique(vlist))
  
  if (length(unique(vlist)) == 1){
    if (unique(vlist) == 3){
    slope_type = "Consistent-high"
    } else if (unique(vlist) == 2) {
    slope_type = "Consistent-medium"
    } else if (unique(vlist) == 1){
    slope_type = "Consistent-low"
    }
  } else {
    if (all(diff(slist) >= 0)) {
      slope_type = "Accumulation"
    } else if (all(diff(slist) <= 0)){
      # print("Satisfied")
      slope_type = "Dissipation"
    } else {
      slope_type = "Fluctuating"
    }
  }
  # print(paste0("Slope type found: ", slope_type))
  return(slope_type)
}

```

## Create function to get trajectory
```{r}

get_var_profile <- function(df, variable, wake_period_name){
  wake_subset_df <- subset(df, df$wake_period == wake_period_name & df$Q_ID == variable)
  # wake_subset_df <- subset(wake_subset_df, wake_subset_df$)
  # wake_subset_df <- subset(wake_subset_df, wake_subset_df$Q_ID == variable)
  # print(variable)
  if (nrow(wake_subset_df) > 2){
    min_rows_needed = 3
    total_available <- nrow(wake_subset_df)
    if (total_available >= 5){
      to_sample = 5
    } else {
      to_sample = 3
    }
    wake_subset_df <- wake_subset_df[sample(nrow(wake_subset_df), to_sample), ]
    slope_list <- c()
    val_list = wake_subset_df$Answer_score
    # print(val_list)
    for (i in 1:nrow(wake_subset_df) - 1){
      del_y <- wake_subset_df$Answer_score[i + 1] - wake_subset_df$Answer_score[i]
      # print(paste0("del_y: ", del_y))
      del_x <- as.numeric(difftime(wake_subset_df$prompt_date_time[i + 1], wake_subset_df$prompt_date_time[i], units = "hours"))
      # print(paste0("del_x: ", del_x))
      slope <- del_y/del_x
      # print(paste0("slope: ", slope))
      slope_list <- c(slope_list, slope)
    }
    profile_type <- get_slope_type(slope_list, val_list)
    return(profile_type)
  } else {
    return(NA)
  }
}

```

## Generate temporal profile for each variable for p_id
```{r}

get_var_profile_df <- function(df, p_id){
  # print(paste0("P_id: ", p_id))
  
  var_list_local <- unique(df$Q_ID)
  # print(paste0("var_list_local: ", var_list_local))
  wake_period_list_local <- unique(df$wake_period)
  # print(paste0("wake_period_list_local: ", wake_period_list_local))
  # print(paste0("Length of wake period: ", length(wake_period_list_local)))
  var_profile_df <- matrix(ncol = length(var_list_local) + 2, nrow = length(wake_period_list_local))

  for (i in 1:length(wake_period_list_local)){
    # print(paste0("i: ", i))
    
    var_profile_df[i, 1] <- p_id
    # print(var_profile_df[i, 1])
    var_profile_df[i, 2] <- wake_period_list_local[[i]][1]
    for (j in 1:length(var_list_local)){
      var_profile_df[i, j + 2] <- get_var_profile(df, var_list_local[[j]][1], wake_period_list_local[[i]][1])
    }
    
  }

  var_profile_df <- as.data.frame(var_profile_df)
  col_names <- c("p_id", "wake_period", var_list_local)
  
  names(var_profile_df) <- col_names
  return (var_profile_df)
}



```

## Get p_id_list
```{r}
p_id_list <- unique(time_daily_long_df$P_ID)
```

## Test function to explore user data
```{r}

p_id <- "neutergoldfishsworn@timestudy_com"
# p_id <- "sharpnessnextpouch@timestudy_com"

pid_subset_df <- prepare_pid_subset(time_daily_long_df, combined_report_df, p_id)

pid_var_profile_df <- get_var_profile_df(pid_subset_df, p_id)

# pid_var_dist_plot <- get_profile_dist_plot(pid_var_profile_df)

## For varianc eonly
# pid_variance_df <- get_variance_df(pid_subset_df, p_id)


```

## Get trajectories for all the participants
Looping through the participant list to get the rowbinded trajectory data frame for each participant

First create a combined function of getting subsets and then feeding subsets to the var profile
```{r}

get_trajectories_df <- function(response_df, report_df, user_id){
  user_id_subset <- prepare_pid_subset(response_df, report_df, user_id)
  user_var_profile_df <- get_var_profile_df(user_id_subset, user_id)
  return(user_var_profile_df)
}

```


```{r}

combined_df = data.frame()

for (username in p_id_list){
  # print(username)
  temp_pid_df <- get_trajectories_df(time_daily_long_df, combined_report_df, username)
  # head(temp_pid_df)
  combined_df <- rbind(combined_df, temp_pid_df)
  # tail(combined_df)
}


```

## Save to file
```{r}

write.csv(combined_df, file="D:/new_data_pre_processed/bema_trajectories_combined.csv", quote = FALSE, row.names = FALSE, sep = ",")

```
## Remove the "unknown user" account
```{r}

combined_df <- subset(combined_df, combined_df$p_id != "aditya4_internal@timestudy_com")

```


## Summarize the distribution overall
First, across all users and constructs --> to check if there is a general variability in responses

```{r}
num_waking_hours <- nrow(combined_df)
num_pids <- length(unique(combined_df$p_id))


```

Get the distribution of waking hours
```{r}
get_waking_hr_dist <- function(df){
  dist_table <- table(df$p_id)
  dist_df <- as.data.frame(dist_table)
  max_wh <- max(dist_df$Freq)
  min_wh <- min(dist_df$Freq)
  median_wh <- median(dist_df$Freq)
  return(c(min_wh, median_wh, max_wh))
}
```

Get distribution values
```{r}
dist_wh <- get_waking_hr_dist(combined_df)

```


Count the occurrences of different trajectory types across the dataframe
```{r}



get_trajectory_freqs <- function(df){
  freq_df <- data.frame()
  col_names <- names(df)
  col_names <- col_names[3:ncol(df)]
  for (col in col_names){
    col_table <- table(df[[col]])
    col_df <- as.data.frame(col_table)
    col_df$var_name <- col
    col_df <- col_df %>% select(var_name, everything())
    freq_df <- rbind(freq_df, col_df)
  }
  
  return(freq_df)
}

```

Now get the df
```{r}
trajectory_dist <- get_trajectory_freqs(combined_df)
```

Aggregate for each construct and trajectory type pair
```{r}

trajectory_aggregate_df <- aggregate(.~var_name+Var1, trajectory_dist, sum)

```

Aggregate for each trajectory type --> across all constructs and users

```{r}
trajectory_summary_df <- aggregate(trajectory_dist$Freq,
                by = list(trajectory_dist$Var1),
                FUN = sum)

```

Plot by variable --> heat map
```{r}

traj_plot <- ggplot(trajectory_dist, aes(x = Var1, y = var_name)) + 
  geom_tile(aes(fill = Freq)) + 
  scale_fill_gradient(name = 'Frequency', low = 'white', high = 'red') + 
  ggtitle("Trajectories vs variables") + 
  ylab("Burst EMA constructs") + 
  xlab("Wake period trajectory types") + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = "black"))

```

add %days to trajectory_dist
```{r}
trajectory_dist$var_sum_days <- ave(trajectory_dist$Freq, trajectory_dist$var_name, FUN = sum)

trajectory_dist$perc_days <- trajectory_dist$Freq/trajectory_dist$var_sum_days
```
get construct wise trajectory table
```{r}

construct_trajectory_df <- dcast(trajectory_dist, var_name ~ Var1, value.var="Freq")

```

Get participant-wise construct-trajectory frequencies
```{r}

get_pid_trajectory_freqs <- function(df){
  user_list <- unique(df$p_id)
  user_freq_df <- data.frame()
  for (user in user_list){
    # print(user)
    user_df <- subset(df, df$p_id == user)
    freq_df <- data.frame()
  col_names <- names(user_df)
  col_names <- col_names[3:ncol(user_df)]
  # col_to_remove <- c("sleep")
  # col_names <- col_names[!col_names %in% col_to_remove]
  for (col in col_names){
    # print(col)
    col_table <- table(user_df[[col]])
    # print(col_table)
    if (length(col_table) != 0){
      col_df <- as.data.frame(col_table)
      col_df$var_name <- col
      col_df <- col_df %>% select(var_name, everything())
      col_df$user_name <- user
      col_df <- col_df %>% select(user_name, everything())
      freq_df <- rbind(freq_df, col_df)
    }
    
  }
  user_freq_df <- rbind(user_freq_df, freq_df)
  }
  
  return(user_freq_df)
}


```

Create a uema_df with only 100 TIME days and above
```{r}

combined_df$n <- 1

combined_df$p_id_days <- ave(combined_df$n, combined_df$p_id, FUN = sum)

combined_100_df <- subset(combined_df, combined_df$p_id_days >= 48)

combined_100_df <- combined_100_df[, !names(combined_100_df) %in% c("n", "p_id_days")]

combined_df <- combined_df[, !names(combined_df) %in% c("n", "p_id_days")]

```

Write combined_df to a csv file
```{r}
write.csv(combined_df, file="D:/uema_exploratory_plots/trajectory_plots/bema_merged_df.csv", row.names = FALSE, quote = FALSE)
```


Get the dataframe for the uema_df
```{r}
pid_trajectories_freq_df <- get_pid_trajectory_freqs(combined_100_df)
```


Recode participant id and trajectory id
```{r}
plist <- unique(pid_trajectories_freq_df$user_name)
pindex <- c(1:length(plist))
pindex <- paste("P_", pindex, sep="")
trajectory_mapping <- c("Consistent-high" = "6", "Accumulation" = "5", "Fluctuating" = "4", "Consistent-medium" = "3", "Dissipation" = "2", "Consistent-low" = "1")

pmap_df <- data.frame(plist, pindex)
names(pmap_df) <- c("user_name", "p_index")

pid_trajectories_freq_df <- merge(pid_trajectories_freq_df, pmap_df, by.x = "user_name")
```

map category values
```{r}


pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Consistent-high"] <- "6"
pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Accumulation"] <- "5"
pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Fluctuating"] <- "4"
pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Consistent-medium"] <- "3"
pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Dissipation"] <- "2"
pid_trajectories_freq_df$trajectory_type[pid_trajectories_freq_df$Var1 == "Consistent-low"] <- "1"


```

sort by p_index
```{r}
pid_trajectories_freq_df <- pid_trajectories_freq_df[order(pid_trajectories_freq_df$user_name), ]
```


plot grouped by participant
```{r}

pid_traj_plot <- ggplot(pid_trajectories_freq_df, aes(x = trajectory_type, y = var_name)) + 
  geom_tile(aes(fill = Freq)) + scale_fill_gradient(name = 'Frequency', low = 'white', high = 'red') + 
  ggtitle("Trajectories vs variables") + 
  ylab("Burst EMA constructs") + 
  xlab("Wake period trajectory types") + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  facet_wrap(~p_index, nrow = 5) + 
  theme(strip.text.x = element_text(size = 6, colour = "black", margin = margin(2,0,2,0, "mm"))) + 
  theme(axis.text.x = element_text(size=6, hjust=1), axis.text.y = element_text(size = 6, hjust = 1))


```

Create function to get participant specific plots
```{r}

plot_pid_trajectories <- function(df, id){
  df_subset <- subset(df, df$user_name == id)
  # print(df_subset)
  plot <- ggplot(df_subset, aes(x = trajectory_type, y = var_name)) + geom_tile(aes(fill = Freq)) + scale_fill_gradient(name = 'Frequency', low = 'white', high = 'red') +
    ggtitle(id) + 
    ylab("Burst EMA constructs") + 
    xlab("Wake period trajectory types") + 
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = "black"))
  return(plot)
}


```

## Read in the burst eod summary file
```{r}

burst_eod_merged_df <- read.csv(file="D:/uema_exploratory_plots/trajectory_plots/beod_merged_df.csv", header = TRUE, sep = ",")

```


## Keep only the common user names
```{r}

bema_df <- combined_df

bema_pids <- unique(bema_df$p_id)

eod_df <- subset(burst_eod_merged_df, burst_eod_merged_df$p_id %in% bema_pids)

```



## Rename the columns

Rename uema columns
```{r}

bema_names <- names(bema_df)

new_bema <- c()

for (name in bema_names){
  if (name != "p_id" && name != "wake_period"){
    name <- paste0("bema_", name)
  }
  new_bema <- c(new_bema, name)
}

names(bema_df) <- new_bema

```

Rename EOD columns
```{r}

eod_names <- names(eod_df)

new_eod <- c()

for (name in eod_names){
  name <- tolower(name)
  if (name != "p_id" && name != "wake_period"){
    name <- paste0("eod_", name)
  }
  new_eod <- c(new_eod, name)
}

names(eod_df) <- new_eod

```

## Merge the two dfs
merging by using p_id and wake period only
```{r}

merged_df <-merge(bema_df,eod_df,by=c("p_id","wake_period")) 

```

get the ema uema pair frequency data frame
```{r}

get_var_freq_plot <- function(df, uema_var, ema_var){
  var_only_subset_df <- df[, c(uema_var, ema_var)]
  var_pair_count_df <- as.data.frame(table(var_only_subset_df))
  var_pair_count_df <- subset(var_pair_count_df, var_pair_count_df[[ema_var]] != "_NOT_ANS_")
  # var_pair_count_df <- var_pair_count_df[!is.na(var_pair_count_df[[ema_var]]), ]
  
  eod_order <- c("Not at all", "A little", "Moderately", "Quite a bit", "Extremely", "Very much so")
  var_pair_count_df[[ema_var]] <- factor(var_pair_count_df[[ema_var]], levels = eod_order)
  # print(head(var_pair_count_df))
  g_plot <- ggplot(var_pair_count_df, aes_string(x = ema_var, y = uema_var)) + 
    geom_tile(aes(fill = Freq)) + 
    scale_fill_gradient(name = 'Frequency', low = 'white', high = 'black') + 
    theme(axis.title.y = element_blank()) + 
    ggtitle(paste0(uema_var, " and ", ema_var)) + 
    theme(strip.text.x = element_text(size = 6, colour = "black", margin = margin(2,0,2,0, "mm"))) + 
    theme(axis.text.x = element_text(size=6, hjust=1), axis.text.y = element_text(size = 6, hjust = 1)) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = "black")) +
    theme(plot.title = element_text(size=10))
  return(g_plot)
}

```

get the ema uema pair frequency plot for the selected participant
```{r}

get_pid_var_freq_plot <- function(df, uema_var, ema_var, pid){
  p_id_subset <- subset(df, df$p_id == pid)
  pid_column_df <- p_id_subset[, c(uema_var,ema_var)]
  freq_df <- as.data.frame(table(pid_column_df))
  g_plot <- ggplot(freq_df, aes_string(x = ema_var, y = uema_var)) + 
    geom_tile(aes(fill = Freq)) + 
    scale_fill_gradient(name = 'Frequency', low = 'white', high = 'black') + 
    theme(axis.title.y = element_blank()) + 
    ggtitle(pid) +
    theme(strip.text.x = element_text(size = 6, colour = "black", margin = margin(2,0,2,0, "mm"))) + 
    theme(axis.text.x = element_text(size=6, hjust=1), axis.text.y = element_text(size = 6, hjust = 1))
  return(g_plot)
  
}

```

get rows satisfying peak effects criteria
```{r}

get_peak_effects_df <- function(df, uema_var, ema_var){
  # | var_df[[ema_var]] == "Quite a bit")
  var_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  peak_effects_df <- subset(var_df, (var_df[[uema_var]] == "Accumulation" | var_df[[uema_var]] == "Fluctuating" | var_df[[uema_var]] == "Dissipation") & (var_df[[ema_var]] == "Extremely" | var_df[[ema_var]] == "Quite a bit"))
  return(peak_effects_df)
}

```

get number of rows for peak effects of each construct

```{r}
var_dict <- list(c("bema_stress", "eod_stress"), c("bema_nerv", "eod_nerv"), c("bema_ten", "eod_ten"), c("bema_happ", "eod_happ"), c("bema_fatig", "eod_fatig"), c("bema_rel", "eod_rel"), c("bema_sad", "eod_sad"), c("bema_foc", "eod_foc"), c("bema_resist", "eod_resist"), c("bema_frust", "eod_frust"))

```

Run a loop for all variable pairs of interest for peak effects
```{r}

var_list <- c()
count_list <- c()
total_meas_list <- c()

for (vars in var_dict){
  # print(vars[[1]])
  temp_df <- get_peak_effects_df(merged_df, vars[[1]], vars[[2]])
  total_observation <- nrow(temp_df)
  var_name <- strsplit(vars[[1]], 'bema_')[[1]][2]
  # print(var_name)
  # var_name <- vars[[1]]
  var_search <- vars[[1]]
  total_uema_count <- length(na.omit(merged_df[[var_search]]))
  var_list <- c(var_list, var_name)
  count_list <- c(count_list, total_observation)
  total_meas_list <- c(total_meas_list, total_uema_count)
}

peak_effects_df <- data.frame(var_list, count_list, total_meas_list)

peak_effects_df$perc <- peak_effects_df$count_list/peak_effects_df$total_meas_list

```

get peak effects for all the constructs
```{r}


var_list <- c()
count_list <- c()
total_meas_list <- c()
total_traj_list <- c()

for (vars in var_dict){
  # print(vars[[1]])
  temp_df <- get_peak_effects_df(merged_df, vars[[1]], vars[[2]])
  total_observation <- nrow(temp_df)
  var_name <- strsplit(vars[[1]], 'bema_')[[1]][2]
  # print(var_name)
  # var_name <- vars[[1]]
  var_search <- vars[[1]]
  total_uema_count <- length(na.omit(merged_df[[var_search]]))
  varying_answers <- c("Accumulation", "Fluctuating", "Dissipation")
  total_extreme_count <- length(merged_df[[var_search]][merged_df[[var_search]] %in% varying_answers])
  var_list <- c(var_list, var_name)
  count_list <- c(count_list, total_observation)
  total_meas_list <- c(total_meas_list, total_uema_count)
  total_traj_list <- c(total_traj_list, total_extreme_count)
}

peak_effects_df <- data.frame(var_list, count_list, total_meas_list, total_traj_list)

peak_effects_df$total_perc <- peak_effects_df$count_list*100/peak_effects_df$total_meas_list
peak_effects_df$peak_day_percs <- peak_effects_df$count_list*100/peak_effects_df$total_traj_list

```


Function to create long format extreme/peak effects df
```{r}
get_long_format_var_df <- function(df, uema_var, ema_var, effect_type){
  var_subset_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  if (effect_type == "extreme_mapping"){
    var_subset_df <- subset(var_subset_df, var_subset_df[[uema_var]] == "Consistent-high" | var_subset_df[[uema_var]] == "Consistent-low")
  } else if (effect_type == "peak_effects"){
    var_subset_df <- subset(var_subset_df, var_subset_df[[uema_var]] == "Accumulation" | var_subset_df[[uema_var]] == "Fluctuating" | var_subset_df[[uema_var]] == "Dissipation")
  }
  
  var_subset_df$comparison_vars <- paste0(uema_var, "--", ema_var)
  names(var_subset_df) <- c("p_id", "wake_period", "bema", "eod", "comparison_vars")
  
  return(var_subset_df)
}

```


Function for reshaping the merged data frame for all the cases
```{r}

get_merged_long_df <- function(df, uema_var, ema_var){
  var_subset_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  var_subset_df$uema_type <- uema_var
  var_subset_df$eod_type <- ema_var
  names(var_subset_df) <- c("p_id", "wake_period", "bema", "eod", "bema_type", "eod_type")
  allowed_eod_answers <- c("Very much so", "Extremely", "Quite a bit", "Moderately", "A little", "Not at all")
  var_subset_df <- subset(var_subset_df, var_subset_df$eod %in% allowed_eod_answers)
  return(var_subset_df)
}

```

Collapse all variables into one
```{r}

merged_long_df <- data.frame()

for (vars in var_dict){
  uema_var <- vars[[1]]
  eod_var <- vars[[2]]
  
  temp_df <- get_merged_long_df(merged_df, uema_var = uema_var, ema_var = eod_var)
  merged_long_df <- rbind(merged_long_df, temp_df)
}

write.csv(merged_long_df, file = "D:/uema_exploratory_plots/trajectory_plots/bema_eod_merged_long_df.csv", sep = ",", row.names = FALSE, quote = FALSE)


```

get rows satisfying extreme mapping. i.e., consistent-high --> extrememly or very much so and consistent-low --> not at all
```{r}

get_extreme_mapping_df <- function(df, uema_var, ema_var){
  var_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  extreme_mapping_df <- subset(var_df, (var_df[[uema_var]] == "Consistent-high" & (var_df[[ema_var]] == "Extremely" | var_df[[ema_var]] == "Very much so")) | (var_df[[uema_var]] == "Consistent-low" & var_df[[ema_var]] == "Not at all"))
  return(extreme_mapping_df)
}

```


Disaggregate extreme mapping for consistent-high and consistent-low
```{r}

get_ch_extreme_df <- function(df, uema_var, ema_var){
  # | var_df[[ema_var]] == "Quite a bit"
  var_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  extreme_mapping_df <- subset(var_df, (var_df[[uema_var]] == "Consistent-high" & (var_df[[ema_var]] == "Extremely" | var_df[[ema_var]] == "Very much so" | var_df[[ema_var]] == "Quite a bit")))
  return(extreme_mapping_df)
}

```

For consistent-low
```{r}

get_cl_notatall_df <- function(df, uema_var, ema_var){
  var_df <- df[, c("p_id", "wake_period", uema_var, ema_var)]
  extreme_mapping_df <- subset(var_df, (var_df[[uema_var]] == "Consistent-low" & var_df[[ema_var]] == "Not at all"))
  return(extreme_mapping_df)
}

```

Run a loop for all variable pairs of interest for peak effects
```{r}

var_list <- c()
count_list <- c()
total_meas_list <- c()
total_traj_list <- c()

for (vars in var_dict){
  # print(vars[[1]])
  ## Replace with approapriate functions here -- get_extreme_mapping_df, get_cl_notatall_df, get_ch_extreme_df
  temp_df <- get_cl_notatall_df(merged_df, vars[[1]], vars[[2]])
  total_observation <- nrow(temp_df)
  var_name <- strsplit(vars[[1]], 'bema_')[[1]][2]
  # print(var_name)
  # var_name <- vars[[1]]
  var_search <- vars[[1]]
  total_uema_count <- length(na.omit(merged_df[[var_search]]))
  # extreme_answers <- c("Consistent-high", "Consistent-low")
  # extreme_answers <- c("Consistent-high")
  extreme_answers <- c("Consistent-low")
  total_extreme_count <- length(merged_df[[var_search]][merged_df[[var_search]] %in% extreme_answers])
  var_list <- c(var_list, var_name)
  count_list <- c(count_list, total_observation)
  total_meas_list <- c(total_meas_list, total_uema_count)
  total_traj_list <- c(total_traj_list, total_extreme_count)
}

extreme_mapping_df <- data.frame(var_list, count_list, total_meas_list, total_traj_list)

extreme_mapping_df$total_perc <- extreme_mapping_df$count_list*100/extreme_mapping_df$total_meas_list
extreme_mapping_df$extreme_day_perc <- extreme_mapping_df$count_list*100/extreme_mapping_df$total_traj_list

```



