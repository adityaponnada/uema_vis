---
title: "parse_burst_ema_data"
author: "Aditya Ponnada"
date: "6/7/2021"
output: html_document
---
## Import libraries
```{r}
library(psych)
library(dplyr)
library(plyr)
library(reshape2)

```

## Read and combine the csv files for EOD
```{r}
pre_process_root_path = "D:/new_data_pre_processed/ema_promptresponse/"

# file_pattern <- paste0(pre_process_root_path, '/*/phone_promptresponse_clean_*.csv')
file_pattern <- paste0(pre_process_root_path, '/*@timestudy_com.csv')
```

## Combine and read all the files for EMA
```{r}

pattern_files_found <- Sys.glob(file_pattern)

# list_of_files <- list.files(pattern_files_found, recursive = TRUE, full.names = TRUE)
list_of_files <- list.files(path = pre_process_root_path, pattern = NULL, full.names = TRUE)

# combined_uema_file <- do.call(plyr::rbind.fill(), lapply(pattern_files_found, read.csv))
combined_ema_file <- ldply(list_of_files, read.csv, header = TRUE, na.strings = c("", "NA"))

```


## Filter out daily prompts on TIME days
```{r}

# combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "Daily" & combined_ema_file$Study_Mode == "TIME")
combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "EMA" & combined_ema_file$Study_Mode == "BURST")

```

## Remove never prompted
```{r}
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status != "NeverPrompted")
```


## Filter out never started or neverprompted prompts
```{r}
include_status <- c("Started", "Completed", "PartiallyCompleted")
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status %in% include_status)
```


## Filter out unwanted columns
```{r}

combined_ema_time_daily_df <- combined_ema_time_daily_df[, c(1:109)]

```

## get column pair lists
```{r}
question_column_set_list <- names(combined_ema_time_daily_df[, c(34:109)])
```

First describe the set types:
Question ID columns 1, 5, ... i = 1, i + 4
Question_text columns, 2, 6, ... i = 2, i + 4
Answer_text columns, 3, 7 ... i = 3, i + 4
Answer_time columns, 4, 8, ... i = 4, i + 4
```{r}

get_column_type_list <- function(start_index, col_list){
  
  type_list <- c()
  num_iters <- length(col_list)/4
  for (i in 1:num_iters){
    type_list <- c(type_list, col_list[[start_index]])
    start_index = start_index + 4
    
  }
  
  return(type_list)
  
}

```

## Get type lists
```{r}
Q_ID_cols <- get_column_type_list(1, question_column_set_list)
Q_text_cols <- get_column_type_list(2, question_column_set_list)
ans_text_cols <- get_column_type_list(3, question_column_set_list)
ans_time_cols <- get_column_type_list(4, question_column_set_list)
```

## Convert to long format
```{r}

time_daily_long_df <- reshape(combined_ema_time_daily_df, direction="long", 
        varying=list(Q_ID_cols, Q_text_cols, ans_text_cols, ans_time_cols), 
        v.names=c("Q_D","Q_TEXT","ANS_TEXT", "ANS_TIME"))

```

## Group by P_ID and then sort by time
```{r}
time_daily_long_df <- time_daily_long_df[order(time_daily_long_df$Participant_ID, time_daily_long_df$Initial_Prompt_Local_Time), ]
```

## Filter out unwanted questions
```{r}
questions_to_include <- c("Q1_SAD", "Q2_HAPP", "Q3_FATIG", "Q4_END", "Q5_REL", "Q6_TEN", "Q7_STRESS", "Q8_FRUST", "Q9_NERV", "Q10_FOC", "Q11_RESIST", "Q12_DEM", "Q14_ROUT", "Q15_SICK")
```

Only select these rows
```{r}
time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$Q_D %in% questions_to_include)
```

## Convert the prompt time to date time object
```{r}
time_daily_long_df$prompt_date_time <- as.POSIXct(time_daily_long_df$Initial_Prompt_Local_Time, format="%Y-%m-%d %H:%M:%OS")
```

## Temporarily remove data before june 1 2020
```{r}
filter_date <- as.POSIXct("2020-06-01 00:00:00.000", format="%Y-%m-%d %H:%M:%OS")

time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$prompt_date_time >= filter_date)
```

## Remove the Q* from question id
```{r}

# pattern = "[Q]{1}\d{1,2}_"

time_daily_long_df$Q_ID <- gsub('[Q]{1}\\d{1,2}_', '', time_daily_long_df$Q_D)

```

Convert the question text to quotes
```{r}
time_daily_long_df$Q_TEXT <- paste0("'", time_daily_long_df$Q_TEXT, "'")
```


## Read the daily report file
```{r}


combined_report_file = paste0('D:/new_data_pre_processed', '/combined_report_N70.csv')
combined_report_df <- read.csv(combined_report_file, header = TRUE, sep = ',')

```

## Convert sleep wake times to date time objects
```{r}


combined_report_df$current_wake_time <- as.POSIXct(combined_report_df$current_wake_time, format="%Y-%m-%d %H:%M:%S")
combined_report_df$current_sleep_time <- as.POSIXct(combined_report_df$current_sleep_time, format="%Y-%m-%d %H:%M:%S")

```

## Rescore burst EMA
Scoring method:
Extremely, Very much so, and quite a bit --> "Yes" --> 3
Moderately, a little --> 2 (sort of)
Not at all --> No --> 1
```{r}

time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Extremely" | time_daily_long_df$ANS_TEXT == "Quite a bit" | time_daily_long_df$ANS_TEXT == "Very much so"] <- 3
time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Moderately" | time_daily_long_df$ANS_TEXT == "A little"] <- 2
time_daily_long_df$Answer_score[time_daily_long_df$ANS_TEXT == "Not at all"] <- 1


```

## Add domain to P-ID

```{r}

time_daily_long_df$P_ID <- paste0(time_daily_long_df$Participant_ID,  "@timestudy_com")

```


## Convert question id to lower case
```{r}

time_daily_long_df$Q_ID <- tolower(time_daily_long_df$Q_ID)

```



## create a subset for participant
uEMA combined file

```{r}

get_bEMA_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$P_ID == p_id)
  return(pid_df)
}

```

Combined report file
```{r}

get_report_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$participant_ID == p_id)
  pid_df <- subset(pid_df, pid_df$study_mode == "BURST")
  return(pid_df)
}

```

## Create a subset for the construct
uEMA combined file

```{r}

get_bEMA_pid_var_df <- function(df, variable){
  var_df <- subset(df, df$Q_ID == variable)
  return(var_df)
}

```

## get p_id_subset
```{r}

prepare_pid_subset <- function(df, report_df, p_id) {
  # print(p_id)
  pid_subset_df <- get_bEMA_pid_df(df, p_id)
  # print(head(pid_subset_df))
  pid_report_df <- get_report_pid_df(report_df, p_id)
  # print(head(pid_report_df))
  # pid_subset_df <- subset(pid_subset_df, pid_subset_df$Q_ID != "activity")
  nrow_report <- nrow(pid_report_df)
  
  for(i in 1:nrow(pid_report_df)){
    # print(i)
  # print(paste0(i, " _ ", pid_report_df$current_wake_time[i]))
  pid_subset_df$wake_period[pid_subset_df$prompt_date_time >= pid_report_df$current_wake_time[i] & pid_subset_df$prompt_date_time <= pid_report_df$current_sleep_time[i]] <- paste0("Wake_period_", i)
  # print(paste0("Wake_period_", i))
  }
  
  return(pid_subset_df)
  
}

```

Add a test function to get the wake period along with prompt response file for all participants
```{r}

plist <- unique(time_daily_long_df$P_ID)

bema_wp_df <- data.frame()

for (pid in plist){
  p_temp_df <- prepare_pid_subset(time_daily_long_df, combined_report_df, pid)
  bema_wp_df <- rbind(bema_wp_df, p_temp_df)
}

```

write the dataframe to a csv file
```{r}
write.csv(bema_wp_df, file="D:/uema_exploratory_plots/trajectory_plots/bema_wp_export.csv", row.names = FALSE, quote = FALSE, sep = ",")
```


## Create a slope type function
```{r}

get_slope_type <- function(slist, vlist){
  slope_type = ""
  slist <- slist[!is.na(slist)]
  vlist <- vlist[!is.na(vlist)]
  # print("Slope list: ")
  # print(slist)
  # print("value list: ")
  # print(vlist)
  # print(length(unique(vlist)))
  # print(unique(vlist))
  
  if (length(unique(vlist)) == 1){
    if (unique(vlist) == 3){
    slope_type = "Consistent-high"
    } else if (unique(vlist) == 2) {
    slope_type = "Consistent-medium"
    } else if (unique(vlist) == 1){
    slope_type = "Consistent-low"
    }
  } else {
    if (all(diff(slist) >= 0)) {
      slope_type = "Accumulation"
    } else if (all(diff(slist) <= 0)){
      # print("Satisfied")
      slope_type = "Dissipation"
    } else {
      slope_type = "Fluctuating"
    }
  }
  # print(paste0("Slope type found: ", slope_type))
  return(slope_type)
}

```

## Create function to get trajectory
```{r}

get_var_profile <- function(df, variable, wake_period_name){
  wake_subset_df <- subset(df, df$wake_period == wake_period_name & df$Q_ID == variable)
  # wake_subset_df <- subset(wake_subset_df, wake_subset_df$)
  # wake_subset_df <- subset(wake_subset_df, wake_subset_df$Q_ID == variable)
  # print(variable)
  if (nrow(wake_subset_df) > 2){
    slope_list <- c()
    val_list = wake_subset_df$Answer_score
    # print(val_list)
    for (i in 1:nrow(wake_subset_df) - 1){
      del_y <- wake_subset_df$Answer_score[i + 1] - wake_subset_df$Answer_score[i]
      # print(paste0("del_y: ", del_y))
      del_x <- as.numeric(difftime(wake_subset_df$prompt_date_time[i + 1], wake_subset_df$prompt_date_time[i], units = "hours"))
      # print(paste0("del_x: ", del_x))
      slope <- del_y/del_x
      # print(paste0("slope: ", slope))
      slope_list <- c(slope_list, slope)
    }
    profile_type <- get_slope_type(slope_list, val_list)
    return(profile_type)
  } else {
    return(NA)
  }
}

```

## Generate temporal profile for each variable for p_id
```{r}

get_var_profile_df <- function(df, p_id){
  # print(paste0("P_id: ", p_id))
  
  var_list_local <- unique(df$Q_ID)
  # print(paste0("var_list_local: ", var_list_local))
  wake_period_list_local <- unique(df$wake_period)
  # print(paste0("wake_period_list_local: ", wake_period_list_local))
  # print(paste0("Length of wake period: ", length(wake_period_list_local)))
  var_profile_df <- matrix(ncol = length(var_list_local) + 2, nrow = length(wake_period_list_local))

  for (i in 1:length(wake_period_list_local)){
    # print(paste0("i: ", i))
    
    var_profile_df[i, 1] <- p_id
    # print(var_profile_df[i, 1])
    var_profile_df[i, 2] <- wake_period_list_local[[i]][1]
    for (j in 1:length(var_list_local)){
      var_profile_df[i, j + 2] <- get_var_profile(df, var_list_local[[j]][1], wake_period_list_local[[i]][1])
    }
    
  }

  var_profile_df <- as.data.frame(var_profile_df)
  col_names <- c("p_id", "wake_period", var_list_local)
  
  names(var_profile_df) <- col_names
  return (var_profile_df)
}



```

## Get p_id_list
```{r}
p_id_list <- unique(time_daily_long_df$P_ID)
```

## Test function to explore user data
```{r}

p_id <- "neutergoldfishsworn@timestudy_com"
# p_id <- "sharpnessnextpouch@timestudy_com"

pid_subset_df <- prepare_pid_subset(time_daily_long_df, combined_report_df, p_id)

pid_var_profile_df <- get_var_profile_df(pid_subset_df, p_id)

# pid_var_dist_plot <- get_profile_dist_plot(pid_var_profile_df)

## For varianc eonly
# pid_variance_df <- get_variance_df(pid_subset_df, p_id)


```

## Get trajectories for all the participants
Looping through the participant list to get the rowbinded trajectory data frame for each participant

First create a combined function of getting subsets and then feeding subsets to the var profile
```{r}

get_trajectories_df <- function(response_df, report_df, user_id){
  user_id_subset <- prepare_pid_subset(response_df, report_df, user_id)
  user_var_profile_df <- get_var_profile_df(user_id_subset, user_id)
  return(user_var_profile_df)
}

```


```{r}

combined_df = data.frame()

for (username in p_id_list){
  print(username)
  temp_pid_df <- get_trajectories_df(time_daily_long_df, combined_report_df, username)
  # head(temp_pid_df)
  combined_df <- rbind(combined_df, temp_pid_df)
  # tail(combined_df)
}


```

## Save to file
```{r}

write.csv(combined_df, file="D:/new_data_pre_processed/bema_trajectories_combined.csv", quote = FALSE, row.names = FALSE, sep = ",")

```

