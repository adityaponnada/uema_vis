---
title: "parse_burst_ema_data"
author: "Aditya Ponnada"
date: "6/7/2021"
output: html_document
---
## Import libraries
```{r}
library(psych)
library(dplyr)
library(plyr)
library(reshape2)

```

## Read and combine the csv files for EOD
```{r}
pre_process_root_path = "D:/new_data_pre_processed/ema_promptresponse/"

# file_pattern <- paste0(pre_process_root_path, '/*/phone_promptresponse_clean_*.csv')
file_pattern <- paste0(pre_process_root_path, '/*@timestudy_com.csv')
```

## Combine and read all the files for EMA
```{r}

pattern_files_found <- Sys.glob(file_pattern)

# list_of_files <- list.files(pattern_files_found, recursive = TRUE, full.names = TRUE)
list_of_files <- list.files(path = pre_process_root_path, pattern = NULL, full.names = TRUE)

# combined_uema_file <- do.call(plyr::rbind.fill(), lapply(pattern_files_found, read.csv))
combined_ema_file <- ldply(list_of_files, read.csv, header = TRUE, na.strings = c("", "NA"))

```


## Filter out daily prompts on TIME days
```{r}

# combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "Daily" & combined_ema_file$Study_Mode == "TIME")
combined_ema_time_daily_df <- subset(combined_ema_file, combined_ema_file$Prompt_Type == "EMA" & combined_ema_file$Study_Mode == "BURST")

```

## Remove never prompted
```{r}
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status != "NeverPrompted")
```


## Filter out never started or neverprompted prompts
```{r}
include_status <- c("Started", "Completed", "PartiallyCompleted")
combined_ema_time_daily_df <- subset(combined_ema_time_daily_df, combined_ema_time_daily_df$Answer_Status %in% include_status)
```


## Filter out unwanted columns
```{r}

combined_ema_time_daily_df <- combined_ema_time_daily_df[, c(1:109)]

```

## get column pair lists
```{r}
question_column_set_list <- names(combined_ema_time_daily_df[, c(34:109)])
```

First describe the set types:
Question ID columns 1, 5, ... i = 1, i + 4
Question_text columns, 2, 6, ... i = 2, i + 4
Answer_text columns, 3, 7 ... i = 3, i + 4
Answer_time columns, 4, 8, ... i = 4, i + 4
```{r}

get_column_type_list <- function(start_index, col_list){
  
  type_list <- c()
  num_iters <- length(col_list)/4
  for (i in 1:num_iters){
    type_list <- c(type_list, col_list[[start_index]])
    start_index = start_index + 4
    
  }
  
  return(type_list)
  
}

```

## Get type lists
```{r}
Q_ID_cols <- get_column_type_list(1, question_column_set_list)
Q_text_cols <- get_column_type_list(2, question_column_set_list)
ans_text_cols <- get_column_type_list(3, question_column_set_list)
ans_time_cols <- get_column_type_list(4, question_column_set_list)
```

## Convert to long format
```{r}

time_daily_long_df <- reshape(combined_ema_time_daily_df, direction="long", 
        varying=list(Q_ID_cols, Q_text_cols, ans_text_cols, ans_time_cols), 
        v.names=c("Q_D","Q_TEXT","ANS_TEXT", "ANS_TIME"))

```

## Group by P_ID and then sort by time
```{r}
time_daily_long_df <- time_daily_long_df[order(time_daily_long_df$Participant_ID, time_daily_long_df$Initial_Prompt_Local_Time), ]
```

## Filter out unwanted questions
```{r}
questions_to_include <- c("Q1_SAD", "Q2_HAPP", "Q3_FATIG", "Q4_END", "Q5_REL", "Q6_TEN", "Q7_STRESS", "Q8_FRUST", "Q9_NERV", "Q10_FOC", "Q11_RESIST", "Q12_DEM", "Q14_ROUT", "Q15_SICK")
```

Only select these rows
```{r}
time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$Q_D %in% questions_to_include)
```

## Convert the prompt time to date time object
```{r}
time_daily_long_df$prompt_date_time <- as.POSIXct(time_daily_long_df$Initial_Prompt_Local_Time, format="%Y-%m-%d %H:%M:%OS")
```

## Temporarily remove data before june 1 2020
```{r}
filter_date <- as.POSIXct("2020-06-01 00:00:00.000", format="%Y-%m-%d %H:%M:%OS")

time_daily_long_df <- subset(time_daily_long_df, time_daily_long_df$prompt_date_time >= filter_date)
```

## Remove the Q* from question id
```{r}

# pattern = "[Q]{1}\d{1,2}_"

time_daily_long_df$Q_ID <- gsub('[Q]{1}\\d{1,2}_', '', time_daily_long_df$Q_D)

```

Convert the question text to quotes
```{r}
time_daily_long_df$Q_TEXT <- paste0("'", time_daily_long_df$Q_TEXT, "'")
```


## Read the daily report file
```{r}


combined_report_file = paste0('D:/new_data_pre_processed', '/combined_report_N70.csv')
combined_report_df <- read.csv(combined_report_file, header = TRUE, sep = ',')

```

## Convert sleep wake times to date time objects
```{r}


combined_report_df$current_wake_time <- as.POSIXct(combined_report_df$current_wake_time, format="%Y-%m-%d %H:%M:%S")
combined_report_df$current_sleep_time <- as.POSIXct(combined_report_df$current_sleep_time, format="%Y-%m-%d %H:%M:%S")

```

## Rescore burst EMA
Scoring method:
Extremely, Very much so, and quite a bit --> "Yes" --> 3
Moderately, a little --> 2 (sort of)
Not at all --> No --> 1
```{r}

time_daily_long_df$Answer_scrore[time_daily_long_df$ANS_TEXT == "Extremely" | time_daily_long_df$ANS_TEXT == "Quite a bit" | time_daily_long_df$ANS_TEXT == "Very much so"] <- 3
time_daily_long_df$Answer_scrore[time_daily_long_df$ANS_TEXT == "Moderately" | time_daily_long_df$ANS_TEXT == "A little"] <- 2
time_daily_long_df$Answer_scrore[time_daily_long_df$ANS_TEXT == "Not at all"] <- 1


```

## Add domain to P-ID

```{r}

time_daily_long_df$P_ID <- paste0(time_daily_long_df$Participant_ID,  "@timestudy_com")

```


## Convert question id to lower case
```{r}

time_daily_long_df$Q_ID <- tolower(time_daily_long_df$Q_ID)

```

## Remove unwanted participants
```{r}

```


## create a subset for participant
uEMA combined file

```{r}

get_bEMA_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$P_ID == p_id)
  return(pid_df)
}

```

Combined report file
```{r}

get_report_pid_df <- function(df, p_id){
  pid_df <- subset(df, df$participant_ID == p_id)
  pid_df <- subset(pid_df, pid_df$study_mode == "BURST")
  return(pid_df)
}

```

## Create a subset for the construct
uEMA combined file

```{r}

get_bEMA_pid_var_df <- function(df, variable){
  var_df <- subset(df, df$Q_ID == variable)
  return(var_df)
}

```

## get p_id_subset
```{r}

prepare_pid_subset <- function(df, report_df, p_id) {
  # print(p_id)
  pid_subset_df <- get_bEMA_pid_df(df, p_id)
  # print(head(pid_subset_df))
  pid_report_df <- get_report_pid_df(report_df, p_id)
  # print(head(pid_report_df))
  # pid_subset_df <- subset(pid_subset_df, pid_subset_df$Q_ID != "activity")
  nrow_report <- nrow(pid_report_df)
  
  for(i in 1:nrow(pid_report_df)){
    # print(i)
  # print(paste0(i, " _ ", pid_report_df$current_wake_time[i]))
  pid_subset_df$wake_period[pid_subset_df$prompt_date_time >= pid_report_df$current_wake_time[i] & pid_subset_df$prompt_date_time <= pid_report_df$current_sleep_time[i]] <- paste0("Wake_period_", i)
  # print(paste0("Wake_period_", i))
  }
  
  return(pid_subset_df)
  
}

```

Add a test function to get the wake period along with prompt response file for all participants
```{r}

plist <- unique(time_daily_long_df$P_ID)

bema_wp_df <- data.frame()

for (pid in plist){
  p_temp_df <- prepare_pid_subset(time_daily_long_df, combined_report_df, pid)
  bema_wp_df <- rbind(bema_wp_df, p_temp_df)
}

```

write the dataframe to a csv file
```{r}
write.csv(bema_wp_df, file="D:/uema_exploratory_plots/trajectory_plots/bema_wp_export.csv", row.names = FALSE, quote = FALSE, sep = ",")
```
